{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f64a7c4aa8c138f2a216c055f299fb9",
     "grade": false,
     "grade_id": "cell-757f7449dc485bc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Main.py\n",
    "\n",
    "## Overview\n",
    "\n",
    "The preprocessed data is fed to an encoder that will produce vector representations for words. These are later fed to a decoder, one level at a time that will map ICD9 codes to these reprsenttaions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T22:26:33.533696Z",
     "start_time": "2022-02-01T22:26:33.525609Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17cd37dbc82c1a46157ec9adb81a3844",
     "grade": false,
     "grade_id": "cell-10db081f94b98d02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from gensim.models.poincare import PoincareModel\n",
    "\n",
    "from utils.utils import (\n",
    "    load_lookups,\n",
    "    prepare_instance,\n",
    "    MyDataset,\n",
    "    my_collate,\n",
    "    my_collate_longformer,\n",
    "    early_stop,\n",
    "    save_everything,\n",
    "    prepare_instance_longformer,\n",
    "    prepare_code_title\n",
    ")\n",
    "from utils.options import args\n",
    "from utils.models import pick_model\n",
    "from utils.train_test import train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T22:26:33.662174Z",
     "start_time": "2022-02-01T22:26:33.536043Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fdd12a66d23c25566d9167b74f1f34e",
     "grade": false,
     "grade_id": "cell-d92e9dc996c61070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # logging.basicConfig(level=logging.INFO)\n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "    if args.random_seed != 0:\n",
    "        random.seed(args.random_seed)\n",
    "        np.random.seed(args.random_seed)\n",
    "        torch.manual_seed(args.random_seed)\n",
    "    #    torch.cuda.manual_seed_all(args.random_seed)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    maxInt = sys.maxsize\n",
    "    while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "        try:\n",
    "            csv.field_size_limit(maxInt)\n",
    "            break\n",
    "        except OverflowError:\n",
    "            maxInt = int(maxInt / 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46301c39a6360e38c7814cb9f4f1519a",
     "grade": false,
     "grade_id": "cell-d9212ce110d4dc0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load vocab and other lookups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T22:26:34.088515Z",
     "start_time": "2022-02-01T22:26:33.664247Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(\"loading lookups...\")\n",
    "    dicts = load_lookups(args) # load lookup table for tokens and icd codes\n",
    "\n",
    "    if args.decoder.find(\"CodeTitle\") != -1:\n",
    "        dicts['c2title'] = prepare_code_title(dicts, args, args.num_code_title_tokens)\n",
    "\n",
    "    if args.decoder.find(\"Hyperbolic\") != -1:\n",
    "        print(\"Training hyperbolic embeddings...\")\n",
    "        hierarchy = dicts['hierarchy_dist']\n",
    "        # train poincare (hyperbolic) embeddings\n",
    "        relations = set()\n",
    "        for k, v in hierarchy[4].items():\n",
    "            relations.add(('root', v[0]))\n",
    "            for i in range(4):\n",
    "                relations.add(tuple(v[i:i+2]))\n",
    "        relations = list(relations)\n",
    "        poincare = PoincareModel(relations, args.hyperbolic_dim, negative=10)\n",
    "        poincare.train(epochs=50)\n",
    "        dicts['poincare_embeddings'] = poincare.kv\n",
    "    \n",
    "    if args.decoder == \"CodeTitle\" or args.decoder == \"RandomlyInitialized\" or args.decoder == \"LAATDecoder\":\n",
    "        args.depth = 1\n",
    "\n",
    "    model = pick_model(args, dicts)\n",
    "    print(model)\n",
    "    \n",
    "    if not args.test_model:\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=args.weight_decay, lr=args.lr)\n",
    "    else:\n",
    "        optimizer = None\n",
    "\n",
    "    if args.model.find(\"longformer\") != -1:\n",
    "        prepare_instance_func = prepare_instance_longformer\n",
    "    else:\n",
    "        prepare_instance_func = prepare_instance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing model instances and optimizer for Longformer and LAAT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T22:26:34.576740Z",
     "start_time": "2022-02-01T22:26:34.091155Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7427796cf3b4d5a493bd096d082ac9",
     "grade": false,
     "grade_id": "cell-d28045e592b8f081",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_instances = prepare_instance_func(dicts, args.data_path, args, args.MAX_LENGTH)\n",
    "    print(\"train_instances {}\".format(len(train_instances)))\n",
    "    if args.version != 'mimic2':\n",
    "        dev_instances = prepare_instance_func(dicts, args.data_path.replace('train','dev'), args, args.MAX_LENGTH)\n",
    "        print(\"dev_instances {}\".format(len(dev_instances)))\n",
    "    else:\n",
    "        dev_instances = None\n",
    "    test_instances = prepare_instance_func(dicts, args.data_path.replace('train','test'), args, args.MAX_LENGTH)\n",
    "    print(\"test_instances {}\".format(len(test_instances)))\n",
    "\n",
    "    if args.model.find(\"longformer\") != -1:\n",
    "        collate_func = my_collate_longformer\n",
    "    else:\n",
    "        collate_func = my_collate\n",
    "\n",
    "    train_loader = DataLoader(MyDataset(train_instances), args.batch_size, shuffle=True, collate_fn=collate_func, num_workers=args.num_workers, pin_memory=True)\n",
    "    if args.version != 'mimic2':\n",
    "        dev_loader = DataLoader(MyDataset(dev_instances), 1, shuffle=False, collate_fn=collate_func, num_workers=args.num_workers, pin_memory=True)\n",
    "    else:\n",
    "        dev_loader = None\n",
    "    test_loader = DataLoader(MyDataset(test_instances), 1, shuffle=False, collate_fn=collate_func, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    scheduler = None\n",
    "    if args.model.find(\"LAAT\") != -1 and not args.test_model:\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.scheduler)\n",
    "    \n",
    "    if not args.test_model and args.model.find(\"longformer\") != -1:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr)\n",
    "\n",
    "    test_only = args.test_model is not None\n",
    "\n",
    "    start_depth = 5 - args.depth\n",
    "    cur_depth = 4 if test_only else start_depth\n",
    "\n",
    "    epochs = [int(epoch) for epoch in args.n_epochs.split(',')]\n",
    "    print(f\"Total epochs at each level: {epochs}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model at depth < 5.\n",
    "\n",
    "This paper involves training the model in 5 levels - level 0 through 4. Each level has different number of epochs that can be modified according to our needs and this will have an impact on the run time and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T22:26:34.861688Z",
     "start_time": "2022-02-01T22:26:34.578395Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d140e954c3a28d1e5479935f3ef713e",
     "grade": true,
     "grade_id": "cell-8f9c85ba731d96e5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    " while cur_depth < 5:\n",
    "        metrics_hist = defaultdict(lambda: [])\n",
    "        metrics_hist_te = defaultdict(lambda: [])\n",
    "        metrics_hist_tr = defaultdict(lambda: [])\n",
    "        break_loop = False\n",
    "        if not test_only:\n",
    "            print(\"Training model at depth {}:\".format(cur_depth))\n",
    "            if cur_depth != 0:\n",
    "                if isinstance(model, torch.nn.DataParallel):\n",
    "                    model.module.decoder.change_depth(cur_depth)\n",
    "                else:\n",
    "                    model.decoder.change_depth(cur_depth)\n",
    "        for epoch in range(epochs[cur_depth]):\n",
    "            if epoch == 0 and cur_depth == start_depth and not args.test_model:\n",
    "                model_dir = os.path.join(args.MODEL_DIR, '_'.join([args.model, args.decoder, time.strftime('%b_%d_%H_%M_%S', time.localtime())]))\n",
    "                os.makedirs(model_dir)\n",
    "            elif args.test_model:\n",
    "                model_dir = os.path.dirname(os.path.abspath(args.test_model))\n",
    "\n",
    "            if not test_only and not break_loop:\n",
    "                epoch_start = time.time()\n",
    "                losses = train(args, model, optimizer, scheduler, epoch, args.gpu_list, train_loader, cur_depth)\n",
    "                loss = np.mean(losses)\n",
    "                epoch_finish = time.time()\n",
    "                print(\"epoch finish in %.2fs, loss: %.4f\" % (epoch_finish - epoch_start, loss))\n",
    "            else:\n",
    "                loss = np.nan\n",
    "\n",
    "            fold = 'test' if args.version == 'mimic2' else 'dev'\n",
    "            dev_instances = test_instances if args.version == 'mimic2' else dev_instances\n",
    "            dev_loader = test_loader if args.version == 'mimic2' else dev_loader\n",
    "            if epoch == epochs[cur_depth] - 1:\n",
    "                print(\"last epoch: testing on dev and test sets\")\n",
    "                break_loop = True\n",
    "            \n",
    "            # test on dev\n",
    "            evaluation_start = time.time()\n",
    "            metrics = test(args, model, args.data_path, fold, args.gpu_list, dicts, dev_loader, cur_depth)\n",
    "            evaluation_finish = time.time()\n",
    "            print(\"evaluation finish in %.2fs\" % (evaluation_finish - evaluation_start))\n",
    "            if test_only or break_loop or epoch == epochs[cur_depth] - 1:\n",
    "                metrics_te = test(args, model, args.data_path, \"test\", args.gpu_list, dicts, test_loader, cur_depth)\n",
    "            else:\n",
    "                metrics_te = defaultdict(float)\n",
    "            metrics_tr = {'loss': loss}\n",
    "            metrics_all = (metrics, metrics_te, metrics_tr)\n",
    "\n",
    "            for name in metrics_all[0].keys():\n",
    "                metrics_hist[name].append(metrics_all[0][name])\n",
    "            for name in metrics_all[1].keys():\n",
    "                metrics_hist_te[name].append(metrics_all[1][name])\n",
    "            for name in metrics_all[2].keys():\n",
    "                metrics_hist_tr[name].append(metrics_all[2][name])\n",
    "            metrics_hist_all = (metrics_hist, metrics_hist_te, metrics_hist_tr)\n",
    "\n",
    "            save_everything(args, metrics_hist_all, model, model_dir, None, args.criterion, test_only)\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if test_only or break_loop:\n",
    "                break\n",
    "\n",
    "            if args.criterion in metrics_hist.keys():\n",
    "                if early_stop(metrics_hist, args.criterion, args.patience):\n",
    "                    #stop training, do tests on test and train sets, and then stop the script\n",
    "                    print(\"%s hasn't improved in %d epochs, early stopping...\" % (args.criterion, args.patience))\n",
    "                    break_loop = True\n",
    "                    args.test_model = '%s/model_best_%s.pth' % (model_dir, args.criterion)\n",
    "                    tmp = args.depth\n",
    "                    args.depth = 5 - cur_depth\n",
    "                    model = pick_model(args, dicts)\n",
    "                    args.depth = tmp\n",
    "\n",
    "            if scheduler is not None and args.criterion in metrics_hist.keys():\n",
    "                if early_stop(metrics_hist, args.criterion, args.scheduler_patience):\n",
    "                    scheduler.step()\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        print(f\"{args.criterion} hasn't improved in {args.scheduler_patience} epochs, reduce learning rate to {param_group['lr']}\")\n",
    "\n",
    "        cur_depth += 1\n"
   ]
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW1/HW1.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "832px",
    "left": "419px",
    "top": "110px",
    "width": "311.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
